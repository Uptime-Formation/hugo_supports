---
title: "TP 5 - Logging et monitoring"
draft: false
weight: 1045
---

## Les drivers de logs

Dans Docker, le driver de logs par d√©faut est `json-file`.
Son inconv√©nient majeur est que les logs avec ce driver sont supprim√©s d√®s que le conteneur est supprim√©.

### Utiliser le driver `journald`

- [A l'aide de la documentation](https://docs.docker.com/config/containers/logging/journald/), changeons le driver dans `/etc/docker/daemon.json` pour utiliser le driver `journald`. 
- Relancez le service `docker.service`
- Consultez les logs d'un conteneur gr√¢ce √† `journalctl -f` et le bon label.

Ce driver est utile car les logs sont d√©sormais archiv√©s d√®s leur cr√©ation, tout en permettant d'utiliser les features de filtrage et de rotation de `journald`.

- Remettez le driver par d√©faut (`json-file` ou supprimez le fichier `/etc/docker/daemon.json`), et restartez le service `docker.service` pour ne pas interf√©rer avec la seconde moiti√© de l'exercice : la config Elastic de l'exercice suivant fonctionne avec le driver `json-file`.

## Une stack Elastic

### Centraliser les logs

L'utilit√© d'Elasticsearch est que, gr√¢ce √† une configuration tr√®s simple de son module Filebeat, nous allons pouvoir centraliser les logs de tous nos conteneurs Docker.
Pour ce faire, il suffit d'abord de t√©l√©charger une configuration de Filebeat pr√©vue √† cet effet :

```bash
curl -L -O https://raw.githubusercontent.com/elastic/beats/7.10/deploy/docker/filebeat.docker.yml
```

Renommons cette configuration et rectifions qui poss√®de ce fichier pour satisfaire une contrainte de s√©curit√© de Filebeat :

```bash
mv filebeat.docker.yml filebeat.yml
sudo chown root filebeat.yml
sudo chmod go-w filebeat.yml
```

Enfin, cr√©ons un fichier `docker-compose.yml` pour lancer une stack Elasticsearch :

```yaml
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.5.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    networks:
      - logging-network

  filebeat:
    image: docker.elastic.co/beats/filebeat:7.5.0
    user: root
    depends_on:
      - elasticsearch
    volumes:
      - ./filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - logging-network
    environment:
      - -strict.perms=false

  kibana:
    image: docker.elastic.co/kibana/kibana:7.5.0
    depends_on:
      - elasticsearch
    ports:
      - 5601:5601
    networks:
      - logging-network

networks:
  logging-network:
    driver: bridge
```

Il suffit ensuite de :
- se rendre sur Kibana (port `5601`)
- de configurer l'index en tapant `*` dans le champ indiqu√©, de valider
- et de s√©lectionner le champ `@timestamp`, puis de valider.

L'index n√©cessaire √† Kibana est cr√©√©, vous pouvez vous rendre dans la partie Discover √† gauche (l'ic√¥ne boussole üß≠) pour lire vos logs.

Il est temps de faire un petit `docker stats` pour d√©couvrir l'utilisation du CPU et de la RAM de vos conteneurs !

#### Parenth√®se : Avec WSL
Avec WSL, l'emplacement des logs est assez difficile √† trouver ! Vous pouvez vous aider de cette page pour ce TP : <https://gist.github.com/Bert-R/e5bb77b9ce9c94fdb1a90e4e615ee518>

### _Facultatif :_ Ajouter un n≈ìud Elasticsearch

Puis, √† l'aide de la documentation Elasticsearch et/ou en adaptant de bouts de code Docker Compose trouv√©s sur internet, ajoutez et configurez un n≈ìud Elastic. Toujours √† l'aide de la documentation Elasticsearch, v√©rifiez que ce nouveau n≈ìud communique bien avec le premier.

### _Facultatif_ : ajouter une stack ELK √† `microblog`

<!-- TODO: Fiare avec ma version de l'app et du docker compose -->

Dans la derni√®re version de l'app `microblog`, Elasticsearch est utilis√© pour fournir une fonctionnalit√© de recherche puissante dans les posts de l'app.
Avec l'aide du [tutoriel de Miguel Grinberg](https://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-xix-deployment-on-docker-containers), √©crivez le `docker-compose.yml` qui permet de lancer une stack enti√®re pour `microblog`. Elle devra contenir un conteneur `microblog`, un conteneur `mysql`, un conteneur `elasticsearch` et un conteneur `kibana`.

<!-- ### _Facultatif / avanc√©_ : centraliser les logs de microblog sur ELK

Avec la [documentation de Filebeat](https://www.elastic.co/guide/en/beats/filebeat/current/configuration-autodiscover.html) et des [hints Filebeat](https://www.elastic.co/guide/en/beats/filebeat/current/configuration-autodiscover-hints.html) ainsi que gr√¢ce √† [cette page](https://discuss.elastic.co/t/nginx-filebeat-elk-docker-swarm-help/130512/2), trouvez comment centraliser les logs Flask de l'app `microblog` gr√¢ce au syst√®me de labels Docker de Filebeat.

Tentons de centraliser les logs de
de ces services dans ELK. -->

### *Facultatif :* du monitoring avec *cAdvisor* et *Prometheus*

Suivre ce tutoriel pour du monitoring des conteneurs Docker : <https://prometheus.io/docs/guides/cadvisor/>

On pourra se servir de cette stack Compose : <https://github.com/vegasbrianc/prometheus/>

#### Ressources suppl√©mentaires

Une alternative est Netdata, joli et configur√© pour monitorer des conteneurs _out-of-the-box_ : <https://learn.netdata.cloud/docs/netdata-agent/installation/docker>

On peut aussi regarder du c√¥t√© de Signoz (logging, monitoring et alerting) : https://github.com/SigNoz/signoz

Ou bien Loki : https://grafana.com/docs/loki/latest/setup/install/docker/


Ressources utiles :
- https://github.com/stefanprodan/dockprom
- https://github.com/vegasbrianc/docker-monitoring
- https://grafana.com/grafana/dashboards/179-docker-prometheus-monitoring/